#+TITLE: Домашние задания по курсу машинного обучения

* Задание 1.
** Постановка задачи
 1) Реализовать метрический классификатор kNN
 2) Сделать кросс-валидацию; обосновать выбор числа фолдов для нее
 3) Выполнить визуализацию данных
 4) Настроить классификатор с 2-3 метриками и 2-3 пространственными преобразованиями
 5) Для оценки качества можно использовать метрику accuracy, но лучше - f1-measure
** Датасет
Ссылка: [[https://www.dropbox.com/s/lolwyijk22xu7na/chips.txt?dl=0]]

Датасет представляет собой набор 2d-точек, разбитых на 2 класса.
** Hints
TBD
** FAQ
1) *Вопрос:*
   Как выбиралось количество фолдов для кросс-валидации? Почему именно такое?

   *Ответ:*
   Около 5 фолдов. Датасет очень маленький, поэтому в ином случае фолды будут
   слишком мелкие. Сослаться на слайды первой лекции[fn:1] , стр. 18.

2) *Вопрос:*
   Как правильно подобрать k - количество ближайших соседей, на которых мы
   ориентируемся?

   *Ответ:*
   Аналогично с Leave-One-Out кросс-валидацией (Первая лекция[fn:1], стр. 24)

3) *Вопрос:*
   Что можно делать для улучшения качества классификации, кроме подбора
   гиперпараметров (т. е. числа k, выбора метрики и ядра)?

   *Ответ:*
   Prototype selection и распознавание аномалий (упоминалось в лекции[fn:1]),
   чтобы почистить датасет от кривых данных. Как именно это делать, не
   спрашивают.

4) *Вопрос:*
   Как устроено k-d tree? Как работают kNN-запросы в нем?

   *Ответ:*
   Вспоминаем вычгеом и/или читаем статью[fn:2].
   Обычно достаточно помахать руками и ляпнуть что-нибудь про разделение
   точек по медианам при построении и отсекание квадратиков при запросе.
** Ссылки
[fn:1] Слайды первой лекции: https://www.dropbox.com/sh/0fk38jg1f5ty1oz/AAD8Z_Hf8Gs6EsE3WNCBh2bWa/02-Distance.pdf?dl=0
[fn:2] Nearest Neighbor with k-d trees: [[http://courses.cs.washington.edu/courses/cse599c1/13wi/slides/lsh-hashkernels-annotated.pdf]]
