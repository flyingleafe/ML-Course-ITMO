#+TITLE: Домашние задания по курсу машинного обучения
#+AUTHOR: Dmitry Mukhutdinov
#+LaTeX_CLASS_OPTIONS: [a4paper, unicode]
#+LaTeX_HEADER: \usepackage[a4paper, left=2.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
#+LaTeX_HEADER: \usepackage[russian]{babel}             % Russian translations
#+LaTeX_HEADER: \usepackage{amssymb,amsmath,amsthm}     % Mathematic symbols, theorems, etc.
#+LaTeX_HEADER: \usepackage{styling}                    % Styling for theorems (local)

* Задание 1.
** Постановка задачи
 1) Реализовать метрический классификатор kNN
 2) Сделать кросс-валидацию; обосновать выбор числа фолдов для нее
 3) Выполнить визуализацию данных
 4) Настроить классификатор с 2-3 метриками и 2-3 пространственными преобразованиями
 5) Для оценки качества можно использовать метрику accuracy, но лучше - f1-measure
** Датасет
Ссылка: [[https://www.dropbox.com/s/lolwyijk22xu7na/chips.txt?dl=0]]

Датасет представляет собой набор 2d-точек, разбитых на 2 класса.
** Hints
TBD
** FAQ
1) *Вопрос:*
   Как выбиралось количество фолдов для кросс-валидации? Почему именно такое?

   *Ответ:*
   Около 5 фолдов. Датасет очень маленький, поэтому в ином случае фолды будут
   слишком мелкие. Сослаться на слайды первой лекции[fn:1] , стр. 18.

2) *Вопрос:*
   Как правильно подобрать k - количество ближайших соседей, на которых мы
   ориентируемся?

   *Ответ:*
   Аналогично с Leave-One-Out кросс-валидацией (Первая лекция[fn:1], стр. 24)

3) *Вопрос:*
   Что можно делать для улучшения качества классификации, кроме подбора
   гиперпараметров (т. е. числа k, выбора метрики и ядра)?

   *Ответ:*
   Prototype selection и распознавание аномалий (упоминалось в лекции[fn:1]),
   чтобы почистить датасет от кривых данных. Как именно это делать, не
   спрашивают.

4) *Вопрос:*
   Как устроено k-d tree? Как работают kNN-запросы в нем?

   *Ответ:*
   Вспоминаем вычгеом и/или читаем статью[fn:2].
   Обычно достаточно помахать руками и ляпнуть что-нибудь про разделение
   точек по медианам при построении и отсекание квадратиков при запросе.
** Ссылки

[fn:1] Слайды первой лекции: https://www.dropbox.com/sh/0fk38jg1f5ty1oz/AAD8Z_Hf8Gs6EsE3WNCBh2bWa/02-Distance.pdf?dl=0
[fn:2] Nearest Neighbor with k-d trees: [[http://courses.cs.washington.edu/courses/cse599c1/13wi/slides/lsh-hashkernels-annotated.pdf]]

* Задание 2
** Постановка задачи
1) Реализовать линейную регрессию
2) Настраивать вектор коэффициентов двумя способами - градиентным спуском и
   генетическим алгоритмом
3) Для оценки качества использовать MSE (среднеквадратичную ошибку)
4) Выбирать гиперпараметры можно произвольным образом, но придется обосновать
   свое решение
5) Модель должна уметь дообучаться по произвольным точкам (с консоли, если у вас
   консольное приложение)
** Датасет
Ссылка: [[https://www.dropbox.com/s/eoyz1uvis41xgrw/prices.txt?dl=0]]

Датасет представляет собой зависимость цен на жилье от площади и количества
комнат.
** Hints
1) Нормализуйте свой датасет (сдвиньте точки по каждой оси на среднее значение и
   разделите на стандартное отклонение). Если вы пишете на Python, можно
   воспользоваться готовым инструментом
   `sklearn.preprocessing.StandardScaler`[fn:3].
   Это сильно упростит работу как градиентного спуска, так и эволюционного алгоритма.
2) При реализации эволюционного алгоритма особью является вектор коэффициентов
   \Theta. Для хорошего результата достаточно делать один вид мутации -
   добавление к вектору коэффициентов случайного, нормально распределенного шума
   (в Python сгенерировать случайный вектор из нормального распределения можно с
   помощью функции `numpy.random.randn`[fn:4]). Скрещивание не нужно. С размером
   потомства и процентом выживаемости можно поэкспериментировать,
   экспериментально хорошо работает увеличение популяции в 6 раз и выживаемость
   1/6 популяции.

** Ссылки

[fn:3] Scikit-learn documentation: StandardScaler [[http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html]]
[fn:4] NumPy documentation: numpy.random.randn [[http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html]]
